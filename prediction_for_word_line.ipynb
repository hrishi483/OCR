{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTXf-GbysDUV"
      },
      "source": [
        "\n",
        "\n",
        "## Deep Learning Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su5tKveVmaLY",
        "outputId": "2ba4d82a-6d33-4449-f0dd-f8f4838563eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#--- words.txt ---------------------------------------------------------------#\n",
            "#\n",
            "# iam database word information\n",
            "#\n",
            "# format: a01-000u-00-00 ok 154 1 408 768 27 51 AT A\n",
            "#\n",
            "#     a01-000u-00-00  -> word id for line 00 in form a01-000u\n",
            "#     ok              -> result of word segmentation\n",
            "#                            ok: word was correctly\n",
            "#                            er: segmentation of word can be bad\n",
            "#\n",
            "#     154             -> graylevel to binarize the line containing this word\n",
            "#     1               -> number of components for this word\n",
            "#     408 768 27 51   -> bounding box around this word in x,y,w,h format\n",
            "#     AT              -> the grammatical tag for this word, see the\n",
            "#                        file tagset.txt for an explanation\n",
            "#     A               -> the transcription for this word\n",
            "#\n",
            "a01-000u-00-00 ok 154 408 768 27 51 AT A\n",
            "a01-000u-00-01 ok 154 507 766 213 48 NN MOVE\n",
            "Total training samples: 86810\n",
            "Total validation samples: 4823\n",
            "Total test samples: 4823\n",
            "Maximum length:  21\n",
            "Vocab size:  78\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import StringLookup\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "loaded_model = keras.models.load_model(\"/content/drive/MyDrive/Handwritting OCR 10 epochs\")\n",
        "\n",
        "!wget -q https://github.com/sayakpaul/Handwriting-Recognizer-in-Keras/releases/download/v1.0.0/IAM_Words.zip\n",
        "!unzip -qq IAM_Words.zip\n",
        "!\n",
        "!mkdir data\n",
        "!mkdir data/words\n",
        "\n",
        "!tar -xf IAM_Words/words.tgz -C data/words\n",
        "!mv IAM_Words/words.txt data\n",
        "!head -20 data/words.txt\n",
        "\n",
        "base_path = \"data\"\n",
        "words_list = []\n",
        "\n",
        "words = open(f\"{base_path}/words.txt\", \"r\").readlines()\n",
        "for line in words:\n",
        "    if line[0] == \"#\":\n",
        "        continue\n",
        "    if line.split(\" \")[1] != \"err\":  # We don't need to deal with errored entries.\n",
        "        words_list.append(line)\n",
        "\n",
        "len(words_list)\n",
        "\n",
        "np.random.shuffle(words_list)\n",
        "\n",
        "split_idx = int(0.9 * len(words_list))\n",
        "train_samples = words_list[:split_idx]\n",
        "test_samples = words_list[split_idx:]\n",
        "\n",
        "val_split_idx = int(0.5 * len(test_samples))\n",
        "validation_samples = test_samples[:val_split_idx]\n",
        "test_samples = test_samples[val_split_idx:]\n",
        "\n",
        "assert len(words_list) == len(train_samples) + len(validation_samples) + len(\n",
        "    test_samples\n",
        ")\n",
        "\n",
        "print(f\"Total training samples: {len(train_samples)}\")\n",
        "print(f\"Total validation samples: {len(validation_samples)}\")\n",
        "print(f\"Total test samples: {len(test_samples)}\")\n",
        "\n",
        "\n",
        "base_image_path = os.path.join(base_path, \"words\")\n",
        "\n",
        "\n",
        "def get_image_paths_and_labels(samples):\n",
        "    paths = []\n",
        "    corrected_samples = []\n",
        "    for (i, file_line) in enumerate(samples):\n",
        "        line_split = file_line.strip()\n",
        "        line_split = line_split.split(\" \")\n",
        "\n",
        "        # Each line split will have this format for the corresponding image:\n",
        "        # part1/part1-part2/part1-part2-part3.png\n",
        "        image_name = line_split[0]\n",
        "        partI = image_name.split(\"-\")[0]\n",
        "        partII = image_name.split(\"-\")[1]\n",
        "        img_path = os.path.join(\n",
        "            base_image_path, partI, partI + \"-\" + partII, image_name + \".png\"\n",
        "        )\n",
        "        if os.path.getsize(img_path):\n",
        "            paths.append(img_path)\n",
        "            corrected_samples.append(file_line.split(\"\\n\")[0])\n",
        "\n",
        "    return paths, corrected_samples\n",
        "\n",
        "\n",
        "train_img_paths, train_labels = get_image_paths_and_labels(train_samples)\n",
        "validation_img_paths, validation_labels = get_image_paths_and_labels(validation_samples)\n",
        "test_img_paths, test_labels = get_image_paths_and_labels(test_samples)\n",
        "\n",
        "# Find maximum length and the size of the vocabulary in the training data.\n",
        "train_labels_cleaned = []\n",
        "characters = set()\n",
        "max_len = 0\n",
        "\n",
        "for label in train_labels:\n",
        "    label = label.split(\" \")[-1].strip()\n",
        "    for char in label:\n",
        "        characters.add(char)\n",
        "\n",
        "    max_len = max(max_len, len(label))\n",
        "    train_labels_cleaned.append(label)\n",
        "\n",
        "characters = sorted(list(characters))\n",
        "\n",
        "print(\"Maximum length: \", max_len)\n",
        "print(\"Vocab size: \", len(characters))\n",
        "\n",
        "# Check some label samples.\n",
        "train_labels_cleaned[:10]\n",
        "\n",
        "\n",
        "def clean_labels(labels):\n",
        "    cleaned_labels = []\n",
        "    for label in labels:\n",
        "        label = label.split(\" \")[-1].strip()\n",
        "        cleaned_labels.append(label)\n",
        "    return cleaned_labels\n",
        "\n",
        "\n",
        "validation_labels_cleaned = clean_labels(validation_labels)\n",
        "test_labels_cleaned = clean_labels(test_labels)\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Mapping characters to integers.\n",
        "char_to_num = StringLookup(vocabulary=list(characters), mask_token=None)\n",
        "\n",
        "# Mapping integers back to original characters.\n",
        "num_to_char = StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "padding_token = 99\n",
        "image_width = 128\n",
        "image_height = 32\n",
        "max_len = 21\n",
        "\n",
        "def distortion_free_resize(image, img_size):\n",
        "    w, h = img_size\n",
        "    image = tf.image.resize(image, size=(h, w), preserve_aspect_ratio=True)\n",
        "\n",
        "    # Check tha amount of padding needed to be done.\n",
        "    pad_height = h - tf.shape(image)[0]\n",
        "    pad_width = w - tf.shape(image)[1]\n",
        "\n",
        "    # Only necessary if you want to do same amount of padding on both sides.\n",
        "    if pad_height % 2 != 0:\n",
        "        height = pad_height // 2\n",
        "        pad_height_top = height + 1\n",
        "        pad_height_bottom = height\n",
        "    else:\n",
        "        pad_height_top = pad_height_bottom = pad_height // 2\n",
        "\n",
        "    if pad_width % 2 != 0:\n",
        "        width = pad_width // 2\n",
        "        pad_width_left = width + 1\n",
        "        pad_width_right = width\n",
        "    else:\n",
        "        pad_width_left = pad_width_right = pad_width // 2\n",
        "\n",
        "    image = tf.pad(\n",
        "        image,\n",
        "        paddings=[\n",
        "            [pad_height_top, pad_height_bottom],\n",
        "            [pad_width_left, pad_width_right],\n",
        "            [0, 0],\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    image = tf.transpose(image, perm=[1, 0, 2])\n",
        "    image = tf.image.flip_left_right(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def preprocess_image(image_path, img_size=(image_width, image_height)):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, 1)\n",
        "    image = distortion_free_resize(image, img_size)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "# A utility function to decode the output of the network.\n",
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search.\n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
        "        :, :max_len\n",
        "    ]\n",
        "    # Iterate over the results and get back the text.\n",
        "    output_text = []\n",
        "    for res in results:\n",
        "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
        "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(res)\n",
        "    return output_text\n",
        "\n",
        "\n",
        "# Assuming build_model and preprocess_image are defined in your code\n",
        "prediction_model = keras.models.Model(\n",
        "    loaded_model.get_layer(name=\"image\").input, loaded_model.get_layer(name=\"dense2\").output\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4L-s5G5d7fs_",
        "outputId": "5c023c33-1621-4176-c5e1-ad8ba7aff190"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/WordDetector'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "os.chdir(\"/content/drive/MyDrive/WordDetector\")\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5heSBXtVAym5"
      },
      "source": [
        "## Word Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Yr0Qf8Qm7ssN"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class BBox:\n",
        "    x: int\n",
        "    y: int\n",
        "    w: int\n",
        "    h: int\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DetectorRes:\n",
        "    img: np.ndarray\n",
        "    bbox: BBox\n",
        "\n",
        "\n",
        "def detect(img: np.ndarray,\n",
        "           kernel_size: int,\n",
        "           sigma: float,\n",
        "           theta: float,\n",
        "           min_area: int) -> List[DetectorRes]:\n",
        "    \"\"\"Scale space technique for word segmentation proposed by R. Manmatha.\n",
        "\n",
        "    For details see paper http://ciir.cs.umass.edu/pubfiles/mm-27.pdf.\n",
        "\n",
        "    Args:\n",
        "        img: A grayscale uint8 image.\n",
        "        kernel_size: The size of the filter kernel, must be an odd integer.\n",
        "        sigma: Standard deviation of Gaussian function used for filter kernel.\n",
        "        theta: Approximated width/height ratio of words, filter function is distorted by this factor.\n",
        "        min_area: Ignore word candidates smaller than specified area.\n",
        "\n",
        "    Returns:\n",
        "        List of DetectorRes instances, each containing the bounding box and the word image.\n",
        "    \"\"\"\n",
        "    assert img.ndim == 2\n",
        "    assert img.dtype == np.uint8\n",
        "\n",
        "    # apply filter kernel\n",
        "    kernel = _compute_kernel(kernel_size, sigma, theta)\n",
        "    img_filtered = cv2.filter2D(img, -1, kernel, borderType=cv2.BORDER_REPLICATE).astype(np.uint8)\n",
        "    img_thres = 255 - cv2.threshold(img_filtered, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "    # append components to result\n",
        "    res = []\n",
        "    components = cv2.findContours(img_thres, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
        "    for c in components:\n",
        "        # skip small word candidates\n",
        "        if cv2.contourArea(c) < min_area:\n",
        "            continue\n",
        "        # append bounding box and image of word to result list\n",
        "        x, y, w, h = cv2.boundingRect(c)  # bounding box as tuple (x, y, w, h)\n",
        "        crop = img[y:y + h, x:x + w]\n",
        "        res.append(DetectorRes(crop, BBox(x, y, w, h)))\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def _compute_kernel(kernel_size: int,\n",
        "                    sigma: float,\n",
        "                    theta: float) -> np.ndarray:\n",
        "    \"\"\"Compute anisotropic filter kernel.\"\"\"\n",
        "\n",
        "    assert kernel_size % 2  # must be odd size\n",
        "\n",
        "    # create coordinate grid\n",
        "    half_size = kernel_size // 2\n",
        "    xs = ys = np.linspace(-half_size, half_size, kernel_size)\n",
        "    x, y = np.meshgrid(xs, ys)\n",
        "\n",
        "    # compute sigma values in x and y direction, where theta is roughly the average x/y ratio of words\n",
        "    sigma_y = sigma\n",
        "    sigma_x = sigma_y * theta\n",
        "\n",
        "    # compute terms and combine them\n",
        "    exp_term = np.exp(-x ** 2 / (2 * sigma_x) - y ** 2 / (2 * sigma_y))\n",
        "    x_term = (x ** 2 - sigma_x ** 2) / (2 * np.math.pi * sigma_x ** 5 * sigma_y)\n",
        "    y_term = (y ** 2 - sigma_y ** 2) / (2 * np.math.pi * sigma_y ** 5 * sigma_x)\n",
        "    kernel = (x_term + y_term) * exp_term\n",
        "\n",
        "    # normalize and return kernel\n",
        "    kernel = kernel / np.sum(kernel)\n",
        "    return kernel\n",
        "\n",
        "\n",
        "def prepare_img(img: np.ndarray,\n",
        "                height: int) -> np.ndarray:\n",
        "    \"\"\"Convert image to grayscale image (if needed) and resize to given height.\"\"\"\n",
        "    assert img.ndim in (2, 3)\n",
        "    assert height > 0\n",
        "    assert img.dtype == np.uint8\n",
        "    if img.ndim == 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    h = img.shape[0]\n",
        "    factor = height / h\n",
        "    return cv2.resize(img, dsize=None, fx=factor, fy=factor)\n",
        "\n",
        "\n",
        "def _cluster_lines(detections: List[DetectorRes],\n",
        "                   max_dist: float = 0.7,\n",
        "                   min_words_per_line: int = 2) -> List[List[DetectorRes]]:\n",
        "    # compute matrix containing Jaccard distances (which is a proper metric)\n",
        "    num_bboxes = len(detections)\n",
        "    dist_mat = np.ones((num_bboxes, num_bboxes))\n",
        "    for i in range(num_bboxes):\n",
        "        for j in range(i, num_bboxes):\n",
        "            a = detections[i].bbox\n",
        "            b = detections[j].bbox\n",
        "            if a.y > b.y + b.h or b.y > a.y + a.h:\n",
        "                continue\n",
        "            intersection = min(a.y + a.h, b.y + b.h) - max(a.y, b.y)\n",
        "            union = a.h + b.h - intersection\n",
        "            iou = np.clip(intersection / union if union > 0 else 0, 0, 1)\n",
        "            dist_mat[i, j] = dist_mat[j, i] = 1 - iou  # Jaccard distance is defined as 1-iou\n",
        "\n",
        "    dbscan = DBSCAN(eps=max_dist, min_samples=min_words_per_line, metric='precomputed').fit(dist_mat)\n",
        "\n",
        "    clustered = defaultdict(list)\n",
        "    for i, cluster_id in enumerate(dbscan.labels_):\n",
        "        if cluster_id == -1:\n",
        "            continue\n",
        "        clustered[cluster_id].append(detections[i])\n",
        "\n",
        "    res = sorted(clustered.values(), key=lambda line: [det.bbox.y + det.bbox.h / 2 for det in line])\n",
        "    return res\n",
        "\n",
        "\n",
        "def sort_multiline(detections: List[DetectorRes],\n",
        "                   max_dist: float = 0.7,\n",
        "                   min_words_per_line: int = 2) -> List[List[DetectorRes]]:\n",
        "    \"\"\"Cluster detections into lines, then sort the lines according to x-coordinates of word centers.\n",
        "\n",
        "    Args:\n",
        "        detections: List of detections.\n",
        "        max_dist: Maximum Jaccard distance (0..1) between two y-projected words to be considered as neighbors.\n",
        "        min_words_per_line: If a line contains less words than specified, it is ignored.\n",
        "\n",
        "    Returns:\n",
        "        List of lines, each line itself a list of detections.\n",
        "    \"\"\"\n",
        "    lines = _cluster_lines(detections, max_dist, min_words_per_line)\n",
        "    res = []\n",
        "    for line in lines:\n",
        "        res += sort_line(line)\n",
        "    return res\n",
        "\n",
        "\n",
        "def sort_line(detections: List[DetectorRes]) -> List[List[DetectorRes]]:\n",
        "    \"\"\"Sort the list of detections according to x-coordinates of word centers.\"\"\"\n",
        "    return [sorted(detections, key=lambda det: det.bbox.x + det.bbox.w / 2)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRrzY7HiAyCK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keA2C6YXAx_D"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3sGNLCEAx8Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5oqrlrqAx5z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uRi93QkAx2K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9V0F1GaAxv5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "kzDgXtux9W88",
        "outputId": "e3846067-2006-4f17-bbac-a375bf6638d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file /content/drive/MyDrive/WordDetector/data/line/1.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-3d46eb02478b>:47: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  colors = plt.cm.get_cmap('rainbow', num_colors)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 to 95 ---- 5 to 41\n",
            "File written successfully: /content/drive/MyDrive/WordDetector/img_names_sequence.txt\n",
            "117 to 230 ---- 15 to 38\n",
            "File written successfully: /content/drive/MyDrive/WordDetector/img_names_sequence.txt\n",
            "248 to 307 ---- 10 to 33\n",
            "File written successfully: /content/drive/MyDrive/WordDetector/img_names_sequence.txt\n",
            "331 to 384 ---- 12 to 36\n",
            "File written successfully: /content/drive/MyDrive/WordDetector/img_names_sequence.txt\n",
            "408 to 472 ---- 3 to 35\n",
            "File written successfully: /content/drive/MyDrive/WordDetector/img_names_sequence.txt\n",
            "491 to 527 ---- 18 to 30\n",
            "File written successfully: /content/drive/MyDrive/WordDetector/img_names_sequence.txt\n",
            "540 to 683 ---- 3 to 41\n",
            "File written successfully: /content/drive/MyDrive/WordDetector/img_names_sequence.txt\n",
            "709 to 856 ---- 14 to 50\n",
            "File written successfully: /content/drive/MyDrive/WordDetector/img_names_sequence.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines  None\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "from typing import List\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "# from word_detector import detect, prepare_img, sort_multiline\n",
        "\n",
        "# Manually set the values or use default values\n",
        "parsed = argparse.Namespace(\n",
        "    # data=[\"/content/drive/MyDrive/WordDetector/data/page/r06-137.png\"],\n",
        "    data = [\"/content/drive/MyDrive/WordDetector/data/line/1.png\"],\n",
        "    kernel_size=25,\n",
        "    sigma=11,\n",
        "    theta=7,\n",
        "    min_area=100,\n",
        "    img_height=50\n",
        ")\n",
        "\n",
        "def get_img_files(data_dir: Path) -> List[Path]:\n",
        "    \"\"\"Return all image files contained in a folder.\"\"\"\n",
        "    res = []\n",
        "    for ext in ['*.png', '*.jpg', '*.bmp']:\n",
        "        res += Path(data_dir).glob(ext)\n",
        "    return res\n",
        "\n",
        "def save_image_names_to_text_files():\n",
        "    # for fn_img in get_img_files(parsed.data):\n",
        "    for fn_img in parsed.data:\n",
        "        print(f'Processing file {fn_img}')\n",
        "\n",
        "        # load image and process it\n",
        "        img = prepare_img(cv2.imread(str(fn_img)), parsed.img_height)\n",
        "        detections = detect(img,\n",
        "                            kernel_size=parsed.kernel_size,\n",
        "                            sigma=parsed.sigma,\n",
        "                            theta=parsed.theta,\n",
        "                            min_area=parsed.min_area)\n",
        "\n",
        "        # sort detections: cluster into lines, then sort each line\n",
        "        lines = sort_multiline(detections)\n",
        "\n",
        "        list_img_names_serial = []\n",
        "        # plot results\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        num_colors = 7\n",
        "        colors = plt.cm.get_cmap('rainbow', num_colors)\n",
        "        for line_idx, line in enumerate(lines):\n",
        "            for word_idx, det in enumerate(line):\n",
        "                xs = [det.bbox.x, det.bbox.x, det.bbox.x + det.bbox.w, det.bbox.x + det.bbox.w, det.bbox.x]\n",
        "                ys = [det.bbox.y, det.bbox.y + det.bbox.h, det.bbox.y + det.bbox.h, det.bbox.y, det.bbox.y]\n",
        "                plt.plot(xs, ys, c=colors(line_idx % num_colors))\n",
        "                plt.text(det.bbox.x, det.bbox.y, f'{line_idx}/{word_idx}')\n",
        "                # print(det.bbox.x, det.bbox.y, det.bbox.w, det.bbox.h)\n",
        "                print(det.bbox.x,\"to\",det.bbox.x + det.bbox.w,\"----\", det.bbox.y,\"to\",det.bbox.y + det.bbox.h)\n",
        "\n",
        "                try:\n",
        "                  crop_img = img[det.bbox.y:det.bbox.y + det.bbox.h, det.bbox.x:det.bbox.x + det.bbox.w]\n",
        "                  cv2.imwrite(f\"line{line_idx}word{word_idx}.jpg\", crop_img)\n",
        "                  full_img_path = f\"line{line_idx}word{word_idx}.jpg\"\n",
        "                  list_img_names_serial.append(full_img_path)\n",
        "\n",
        "                  list_img_names_serial_set = set(list_img_names_serial)\n",
        "\n",
        "                  output_path = \"/content/drive/MyDrive/WordDetector/img_names_sequence.txt\"  # Change the path accordingly\n",
        "                  with open(output_path, \"w\") as textfile:\n",
        "                      for element in list_img_names_serial:\n",
        "                          textfile.write(element + \"\\n\")\n",
        "\n",
        "                  # Print the path for confirmation\n",
        "                  print(f\"File written successfully: {output_path}\")\n",
        "                except Exception as e:\n",
        "                  print(\"exception\",e)\n",
        "                  if crop_img.shape[0] <= img.shape[0] or crop_img.shape[1] >= img.shape[1]:\n",
        "                      print(f\"Error: Crop dimensions exceed original image dimensions for line {line_idx}, word {word_idx}\")\n",
        "                      print(crop_img.shape[0] , img.shape[0], crop_img.shape[1] , img.shape[1])\n",
        "\n",
        "                  print(\"\",end=\"\")\n",
        "        plt.show()\n",
        "    # return list_img_names_serial_set\n",
        "\n",
        "print(\"Lines \",save_image_names_to_text_files())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OMAfy29gBr9F",
        "outputId": "cf0e9d2e-ce72-4614-e755-76ace9247bde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/WordDetector'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ga8R5LOJpEtc"
      },
      "outputs": [],
      "source": [
        "def predict_for_new_image(path):\n",
        "  # Load and preprocess the new image\n",
        "  # new_image_path = \"/content/of.png\"\n",
        "  new_image_path = path\n",
        "\n",
        "\n",
        "  new_image = preprocess_image(new_image_path)\n",
        "\n",
        "\n",
        "  # Expand dimensions to match the model's expected input shape\n",
        "  new_image = np.expand_dims(new_image, axis=0)\n",
        "\n",
        "  # Get predictions\n",
        "  preds = prediction_model.predict(new_image)\n",
        "\n",
        "  # Decode the predictions\n",
        "  decoded_text = decode_batch_predictions(preds)[0]\n",
        "\n",
        "  # Display the results\n",
        "  print(\"Predicted Text:\", decoded_text.strip(\"[UNK]\"))\n",
        "  return decoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz5c_mtMpU0-",
        "outputId": "00296f64-54d0-4f46-c880-11ade5cab435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n",
            "Predicted Text: of\n"
          ]
        }
      ],
      "source": [
        "predict_for_new_image(\"/content/of.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TYUPQRdpYFE",
        "outputId": "f6b0ce31-730a-4e7d-9ea6-b450b4cdb39e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['IAM_Words.zip.1',\n",
              " 'IAM_Words.zip',\n",
              " 'IAM_Words.zip.2',\n",
              " 'LICENSE.md',\n",
              " 'requirements.txt',\n",
              " 'README.md',\n",
              " '.gitignore',\n",
              " 'setup.py',\n",
              " 'doc',\n",
              " 'tests',\n",
              " 'data',\n",
              " 'examples',\n",
              " 'word_detector.egg-info',\n",
              " 'word_detector',\n",
              " '.git',\n",
              " 'build',\n",
              " 'usage.py',\n",
              " '.ipynb_checkpoints',\n",
              " 'line0word0.jpg',\n",
              " 'line0word1.jpg',\n",
              " 'line0word5.jpg',\n",
              " 'line0word3.jpg',\n",
              " 'line0word2.jpg',\n",
              " 'line0word6.jpg',\n",
              " 'img_names_sequence.txt',\n",
              " 'line0word4.jpg',\n",
              " 'IAM_Words',\n",
              " 'main_draft1.ipynb',\n",
              " 'line0word7.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "os.chdir(\"/content/drive/MyDrive/WordDetector\")\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "LI3ziPrbplUD",
        "outputId": "f5e3aaf8-5bf4-4f37-be5a-a8f227d37f51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "line0word0.jpg\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "Predicted Text: foods\n",
            "line0word1.jpg\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "Predicted Text: woud\n",
            "line0word5.jpg\n",
            "1/1 [==============================] - 0s 141ms/step\n",
            "Predicted Text: un\n",
            "line0word3.jpg\n",
            "1/1 [==============================] - 0s 146ms/step\n",
            "Predicted Text: be\n",
            "line0word2.jpg\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "Predicted Text: still\n",
            "line0word6.jpg\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "Predicted Text: fomiles\n",
            "line0word4.jpg\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Predicted Text: hee\n",
            "line0word7.jpg\n",
            "1/1 [==============================] - 0s 176ms/step\n",
            "Predicted Text: reaong\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'foods woud un be still fomiles hee reaong'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "predicted_line = []\n",
        "for file in os.listdir():\n",
        "  if file.split('.')[-1] in ['jpeg','png','jpg']:\n",
        "    print(file)\n",
        "    predicted_line.append(predict_for_new_image(file))\n",
        "\n",
        "' '.join(predicted_line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCetOX5Jp_mP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}